---
title: "Week 4: Cross-Validation and Model Selection"
subtitle: "*DSAN 5300: Statistical Learning*<br><span class='subsubtitle'>Spring 2025, Georgetown University</span>"
author: "Jeff Jacobs"
institute: "[`jj1088@georgetown.edu`](mailto:jj1088@georgetown.edu)"
bibliography: "../_DSAN5300.bib"
date: 2025-02-03
date-format: full
lecnum: 4
categories:
  - "Class Sessions"
format:
  revealjs:
    df-print: kable
    footer: "DSAN 5300-01 Week 4: {{< var w04.footer >}}"
    output-file: "slides.html"
    html-math-method: mathjax
    scrollable: true
    css: "../dsan-globals/jjstyles.css"
    slide-number: true
    echo: true
    code-fold: true
    link-external-icon: true
    link-external-newwindow: true
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'><link rel='preconnect' href='https://fonts.googleapis.com'><link rel='preconnect' href='https://fonts.gstatic.com' crossorigin><link href='https://fonts.googleapis.com/css2?family=Workbench&display=swap' rel='stylesheet'>"
    simplemenu:
      flat: true
      barhtml:
        header: "<div class='menubar'><span style='position: absolute; left: 8; padding-left: 8px;'><a href='./index.html'>&larr; Return to Notes</a></span><ul class='menu'></ul></div>"
      scale: 0.5
    revealjs-plugins:
      - simplemenu
  html:
    df-print: kable
    output-file: "index.html"
    html-math-method: mathjax
    echo: true
    code-fold: true
    include-in-header:
      text: "<link rel='stylesheet' href='https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css'>"
---

::: {.content-visible unless-format="revealjs"}

<center class='mb-3'>
<a class="h2" href="./slides.html" target="_blank">Open slides in new tab &rarr;</a>
</center>

:::


# Schedule {.smaller .small-title .crunch-title .crunch-callout data-name="Schedule"}

Today's Planned Schedule:

| | Start | End | Topic |
|:- |:- |:- |:- |
| **Lecture** | 6:30pm | 6:40pm | [Logistic Regression Recap &rarr;](#recap-logistic-regression) |
| | 6:40pm | 7:00pm | [CV and Model Selection Motivation &rarr;](#what-we-have-thus-far) |
| | 7:00pm | 8:00pm | [Cross Validation Methods &rarr;](#cross-validation) |
| **Break!** | 8:00pm | 8:10pm | |
| | 8:10pm | 9:00pm | [Quizzo &rarr;](#quiz-time) |

: {tbl-colwidths="[12,12,12,64]"}


::: {.hidden}

```{r}
#| label: r-source-globals
source("../dsan-globals/_globals.r")
set.seed(5300)
```

:::

{{< include ../dsan-globals/_globals-tex.qmd >}}

# Recap: Logistic Regression {.smaller .crunch-ul .math-80 .title-09 data-stack-name="Recap"}

* What happens to the **probability** $\Pr(Y = 1 \mid X)$ when $X$ increases by **1 unit**?
* "Linear Probability Model" $\Pr(Y = 1 \mid X) = \beta_0 + \beta_1X$ fails, **but**, "fixing" it leads to

$$
\begin{align*}
&\log\left[ \frac{\Pr(Y = 1 \mid X)}{1 - \Pr(Y = 1 \mid X)} \right] = \beta_0 + \beta_1 X \\
\iff &\Pr(Y = 1 \mid X) = \frac{\exp[\beta_0 + \beta_1X]}{1 + \exp[\beta_0 + \beta_1X]} = \frac{1}{1 + \exp\left[ -(\beta_0 + \beta_1X) \right] }
\end{align*}
$$

> $\leadsto$ A 1-unit increase in $X$ is associated with a $\beta_1$ increase in the **log-odds** of $Y$

## What We Have Thus Far {.smaller .crunch-title .title-10 .crunch-ul .crunch-img}

* We have a **core model**, regression, that we can **build up** into p much anything we want!

| Class Topic | This Video |
| - | - |
| Linear regression | Pachelbel's *Canon in D* (1m26s-1m46s) |
| Logistic regression | Add swing: ![](images/swing_image.svg){width="100"} (1m46s) |
| Neural networks | (triads $\mapsto$ 7th/9th chords) (5m24s-5m53s) |

{{< video https://www.youtube.com/watch?v=lpc1lEJ-SRc width="100%" height="340" >}}

# Taking Off the Linearity Training Wheels {.smaller data-stack-name="Motivation"}

```{=html}
<style>
@font-face {
    font-family: Noodle;
    src: url('/assets/Kbnoodlemonster.ttf');
}
.workbench-jj {
  font-family: "Workbench", serif;
  /* font-optical-sizing: auto; */
  font-weight: 400;
  font-style: normal;
  font-size: 96pt !important;
}
.noodle-jj {
    font-family: "Noodle", serif;
    font-size: 96pt !important;
}
</style>
```

:::: {.columns}
::: {.column width="50%"}

::: {#fig-workbench}

<center>

[Linear Models]{.workbench-jj}

</center>

[Font Credit](https://fonts.google.com/specimen/Workbench)
:::

:::
::: {.column width="50%"}

::: {#fig-noodle}

<center>

[Linear Models]{.noodle-jj}

</center>

[Font Credit](http://keepinitkoolinkinderland.blogspot.com/p/fonts.html)
:::

:::
::::

## Where Are We Going / What Problems Are We Solving? {.smaller}

* Another nice property we have: OLS estimator is **BLUE** (**B**est **L**inear **U**nbiased **E**stimator) of conditional mean $\mathbb{E}[Y \mid X]$
* The first problem we'll tackle is: as we move **from** linear models with these kinds of guarantees **to** fancier models with more uncertainties / "potholes"... how do we ensure they still achieve want we want them to achieve?
* Tldr: we can study **more complex** relationships between $X$ and $Y$ than linear ones, but we lose guarantees like "If it's linear, then it is [this]": in other words, we lose this **automatic generalizability**
* *(With great[er] power comes great[er] responsibility!)*

## The Level 2 Goal: *Generalizability* {.smaller .crunch-title .crunch-callout .crunch-ul}

::: {.callout-tip .r-fit-text title="<i class='bi bi-info-circle'></i> The Goal of Statistical Learning" icon="false"}

Find...

* A function $\widehat{y} = f(x)$ ‚úÖ
* That best predicts $Y$ for given values of $X$ ‚úÖ
* For data that has not yet been observed! üò≥‚ùì

:::

## ...Can We Just, Like, Not? {.smaller .crunch-title .crunch-ul .crunch-img}

:::: {.columns}
::: {.column width="70%"}

* What happens if we "unleash" fancier non-linear models on data the same way we've been using linear models?
* The evil scourge of... **OVERFITTING** *(‚ö°Ô∏è a single overly-dramatic lightning bolt strikes the whiteboard behind me right at this exact moment what are the odds ‚ö°Ô∏è)*

:::
::: {.column width="30%"}

![Your computer is [Yes Man](https://www.youtube.com/watch?v=g-QSuiXL6lY)](images/yes_man.png){fig-align="center" width="185"}

:::
::::

:::: {.columns}
::: {.column width="50%"}

```{r}
#| label: linear-fit
#| fig-cap: "You: \"Fit the data... but you're only allowed to be linear!\" Computer: \"You got it boss!\""
library(tidyverse)
set.seed(5300)
N <- 30
x_vals <- runif(N, min=0, max=1)
y_vals_raw <- 3 * x_vals
y_noise <- rnorm(N, mean=0, sd=0.5)
y_vals <- y_vals_raw + y_noise
data_df <- tibble(x=x_vals, y=y_vals)
data_df |> ggplot(aes(x=x, y=y)) +
  geom_point(size=2) +
  stat_smooth(
    method="lm",
    formula="y ~ x",
    se=FALSE,
    linewidth=1
  ) +
  labs(
    title = paste0("Linear Regression, N = ",N)
  ) +
  theme_dsan(base_size=28)
```

:::
::: {.column width="50%"}

```{r}
#| label: poly-fit
#| fig-cap: "You: \"Fit the data...\" Computer: \"You got it boss!\""
data_df |> ggplot(aes(x=x, y=y)) +
  geom_point(size=2.5) +
  stat_smooth(
    method="lm",
    formula=y ~ poly(x, N, raw=TRUE),
    se=FALSE,
    linewidth=1
  ) +
  labs(
    title = paste0("Polynomial Regression, N = ",N)
  ) +
  theme_dsan(base_size=28)
```

:::
::::

::: {.notes}

([Image Source](http://www.game-art-hq.com/89202/the-yes-man-from-fallout-game-art-overview/))

:::

## Memorizing Data vs. *Learning* the Relationship {.smaller .crunch-title .title-11 .crunch-quarto-figure .crunch-img}

:::: {.columns}
::: {.column width="60%"}

```{r}
#| label: training-data-plot
#| fig-width: 4.25
#| fig-height: 2.75
#| fig-align: left
x <- seq(from = 0, to = 1, by = 0.1)
n <- length(x)
eps <- rnorm(n, 0, 0.04)
y <- x + eps
# But make one big outlier
midpoint <- ceiling((3/4)*n)
y[midpoint] <- 0
of_data <- tibble::tibble(x=x, y=y)
# Linear model
lin_model <- lm(y ~ x)
# But now polynomial regression
poly_model <- lm(y ~ poly(x, degree = 10, raw=TRUE))
#summary(model)
ggplot(of_data, aes(x=x, y=y)) +
  geom_point(size=g_pointsize/2) +
  labs(
    title = "Training Data",
    color = "Model"
  ) +
  theme_dsan(base_size=16)
```

```{r}
#| label: training-linear-poly
#| fig-width: 6
#| fig-height: 2.75
#| fig-align: left
ggplot(of_data, aes(x=x, y=y)) +
  geom_point(size=g_pointsize/2) +
  geom_abline(aes(intercept=0, slope=1, color="Linear"), linewidth=1, show.legend = FALSE) +
  stat_smooth(method = "lm",
              formula = y ~ poly(x, 10, raw=TRUE),
              se = FALSE, aes(color="Polynomial")) +
  labs(
    title = "A Perfect Model?",
    color = "Model"
  ) +
  theme_dsan(base_size=16)
```

:::
::: {.column width="40%"}

How have we measured "good" fit? High $R^2$? Low $RSS$?

<center>
Linear Model:
</center>

```{r}
#| label: lin-model-metrics
#| echo: true
#| code-fold: show
summary(lin_model)$r.squared
get_rss(lin_model)
```

<center style="margin-top: 20px !important;">
Polynomial Model:
</center>

```{r}
#| label: poly-model-metrics
#| echo: true
#| code-fold: show
summary(poly_model)$r.squared
get_rss(poly_model)
```

:::
::::

## 5000: Accuracy $\leadsto$ 5300: Generalization {.smaller .crunch-title .title-12}

* Training Accuracy: How well does it fit the data we can see?
* Test Accuracy: How well does it **generalize** to future data?

:::: {.columns}
::: {.column width="60%"}

```{r}
#| label: lin-poly-newdata
#| fig-width: 5.5
#| fig-height: 4
# Data setup
x_test <- seq(from = 0, to = 1, by = 0.1)
n_test <- length(x_test)
eps_test <- rnorm(n_test, 0, 0.04)
y_test <- x_test + eps_test
of_data_test <- tibble::tibble(x=x_test, y=y_test)
lin_y_pred_test <- predict(lin_model, as.data.frame(x_test))
#lin_y_pred_test
lin_resids_test <- y_test - lin_y_pred_test
#lin_resids_test
lin_rss_test <- sum(lin_resids_test^2)
#lin_rss_test
# Lin R2 = 1 - RSS/TSS
tss_test <- sum((y_test - mean(y_test))^2)
lin_r2_test <- 1 - (lin_rss_test / tss_test)
#lin_r2_test
# Now the poly model
poly_y_pred_test <- predict(poly_model, as.data.frame(x_test))
poly_resids_test <- y_test - poly_y_pred_test
poly_rss_test <- sum(poly_resids_test^2)
#poly_rss_test
# RSS
poly_r2_test <- 1 - (poly_rss_test / tss_test)
#poly_r2_test
ggplot(of_data, aes(x=x, y=y)) +
  stat_smooth(method = "lm",
              formula = y ~ poly(x, 10, raw = TRUE),
              se = FALSE, aes(color="Polynomial")) +
  theme_classic() +
  geom_point(data=of_data_test, aes(x=x_test, y=y_test), size=g_pointsize/2) +
  geom_abline(aes(intercept=0, slope=1, color="Linear"), linewidth=1, show.legend = FALSE) +
  labs(
    title = "Evaluation: Unseen Test Data",
    color = "Model"
  ) +
  theme_dsan(base_size=16)
```
:::

::: {.column width="40%"}

<center>
Linear Model:
</center>

```{r,echo=TRUE}
#| label: lin-newdata-metrics
#| echo: true
#| code-fold: show
lin_r2_test
lin_rss_test
```

<center style="margin-top: 10px !important;">
Polynomial Model:
</center>

```{r,echo=TRUE}
#| label: poly-newdata-metrics
#| echo: true
#| code-fold: show
poly_r2_test
poly_rss_test
```

:::
::::

## In Other Words...

![Image source: circulated as secret shitposting among PhD students in seminars](images/hypothesis.jpg){fig-align="center"}

## Resampling Methods

* Cross-Validation and Bootstrap

## Model Selection

* Subset Selection
* "Complexity Penalties"
* LASSO ü§†

# Cross-Validation {data-stack-name="Cross Validation"}

## Na√Øve Approach: Validation Set

## Better Approach: LOOCV

## Best Approach: $K$-Fold CV

# Model Selection Preview {data-stack-name="Model Selection"}

## The Goal

* Maximize **generalizability** by
* Penalizing **complexity**

# Quiz Time! {data-name="Quiz 1"}

* Jeff hands out your (paper) quizzes now!
* You have 55 minutes (8:05 to 9pm)
* You got this üí™